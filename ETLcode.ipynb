{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "749478db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col ,isnan,expr,round , when, max\n",
    "from datetime import datetime\n",
    "import psycopg2\n",
    "import boto3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad60aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"FileProcessing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed2827b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"D:\\Custom_assignment\\Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ca9a842a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+---------+-------+\n",
      "|Region|  Product|    Date|UnitsSold|Revenue|\n",
      "+------+---------+--------+---------+-------+\n",
      "| North|Product A|1/1/2022|      100|   null|\n",
      "| North|Product B|1/1/2022|      150|   2000|\n",
      "| South|Product A|1/1/2022|      120|   1500|\n",
      "| South|Product B|    NULL|       80|   1000|\n",
      "|  West|Product A|1/1/2022|       90|   1200|\n",
      "|  West|Product B|1/1/2022|      200|   2500|\n",
      "| North|Product A|1/2/2022|      110|   1200|\n",
      "| North|Product B|1/2/2022|      140|   1800|\n",
      "| South|Product A|1/2/2022|      130|   1600|\n",
      "| South|Product B|1/2/2022|       70|    900|\n",
      "|  West|Product A|1/2/2022|      100|   1300|\n",
      "|  West|Product B|1/2/2022|      190|   2400|\n",
      "| North|     NULL|    NULL|      100|   NULL|\n",
      "+------+---------+--------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(folder_path)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e8ff0ae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+--------+------------------+------------------+\n",
      "|summary|Region|  Product|    Date|         UnitsSold|           Revenue|\n",
      "+-------+------+---------+--------+------------------+------------------+\n",
      "|  count|    13|       13|      13|                13|                12|\n",
      "|   mean|  null|     null|    null|121.53846153846153|1581.8181818181818|\n",
      "| stddev|  null|     null|    null|  39.7588887013864|   540.03366898404|\n",
      "|    min| North|     NULL|1/1/2022|                70|              1000|\n",
      "|    max|  West|Product B|    NULL|               200|              NULL|\n",
      "+-------+------+---------+--------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dc12e4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- UnitsSold: integer (nullable = true)\n",
      " |-- Revenue: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2865cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter( (col('Product').isNotNull()) & (col('UnitsSold').isNotNull()) & (col('Revenue').isNotNull()) & (col('Product') != 'NULL') & (col('Date') != 'NULL') & (col('Revenue') != 'NULL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7a7f7b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+---------+-------+\n",
      "|Region|  Product|    Date|UnitsSold|Revenue|\n",
      "+------+---------+--------+---------+-------+\n",
      "| North|Product B|1/1/2022|      150|   2000|\n",
      "| South|Product A|1/1/2022|      120|   1500|\n",
      "|  West|Product A|1/1/2022|       90|   1200|\n",
      "|  West|Product B|1/1/2022|      200|   2500|\n",
      "| North|Product A|1/2/2022|      110|   1200|\n",
      "| North|Product B|1/2/2022|      140|   1800|\n",
      "| South|Product A|1/2/2022|      130|   1600|\n",
      "| South|Product B|1/2/2022|       70|    900|\n",
      "|  West|Product A|1/2/2022|      100|   1300|\n",
      "|  West|Product B|1/2/2022|      190|   2400|\n",
      "+------+---------+--------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "384ab4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('unit_price', round(expr('revenue/unitsSold'),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3478d45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+---------+-------+----------+\n",
      "|Region|  Product|    Date|UnitsSold|Revenue|unit_price|\n",
      "+------+---------+--------+---------+-------+----------+\n",
      "| North|Product B|1/1/2022|      150|   2000|     13.33|\n",
      "| South|Product A|1/1/2022|      120|   1500|      12.5|\n",
      "|  West|Product A|1/1/2022|       90|   1200|     13.33|\n",
      "|  West|Product B|1/1/2022|      200|   2500|      12.5|\n",
      "| North|Product A|1/2/2022|      110|   1200|     10.91|\n",
      "| North|Product B|1/2/2022|      140|   1800|     12.86|\n",
      "| South|Product A|1/2/2022|      130|   1600|     12.31|\n",
      "| South|Product B|1/2/2022|       70|    900|     12.86|\n",
      "|  West|Product A|1/2/2022|      100|   1300|      13.0|\n",
      "|  West|Product B|1/2/2022|      190|   2400|     12.63|\n",
      "+------+---------+--------+---------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "27b5d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('cost_price', when(col('product') == 'Product A', 11)\n",
    "                                .when(col('product') == 'Product B', 11.2)\n",
    "                                .otherwise(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e6fb6abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+---------+-------+----------+----------+\n",
      "|Region|  Product|    Date|UnitsSold|Revenue|unit_price|cost_price|\n",
      "+------+---------+--------+---------+-------+----------+----------+\n",
      "| North|Product B|1/1/2022|      150|   2000|     13.33|      11.2|\n",
      "| South|Product A|1/1/2022|      120|   1500|      12.5|      11.0|\n",
      "|  West|Product A|1/1/2022|       90|   1200|     13.33|      11.0|\n",
      "|  West|Product B|1/1/2022|      200|   2500|      12.5|      11.2|\n",
      "| North|Product A|1/2/2022|      110|   1200|     10.91|      11.0|\n",
      "| North|Product B|1/2/2022|      140|   1800|     12.86|      11.2|\n",
      "| South|Product A|1/2/2022|      130|   1600|     12.31|      11.0|\n",
      "| South|Product B|1/2/2022|       70|    900|     12.86|      11.2|\n",
      "|  West|Product A|1/2/2022|      100|   1300|      13.0|      11.0|\n",
      "|  West|Product B|1/2/2022|      190|   2400|     12.63|      11.2|\n",
      "+------+---------+--------+---------+-------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "64dbcad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('profit_percent', round(((col('unit_price') - col('cost_price'))*100 / col('unit_price')), 2).cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7ce45bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+---------+-------+----------+----------+--------------+\n",
      "|Region|  Product|    Date|UnitsSold|Revenue|unit_price|cost_price|profit_percent|\n",
      "+------+---------+--------+---------+-------+----------+----------+--------------+\n",
      "| North|Product B|1/1/2022|      150|   2000|     13.33|      11.2|         15.98|\n",
      "| South|Product A|1/1/2022|      120|   1500|      12.5|      11.0|          12.0|\n",
      "|  West|Product A|1/1/2022|       90|   1200|     13.33|      11.0|         17.48|\n",
      "|  West|Product B|1/1/2022|      200|   2500|      12.5|      11.2|          10.4|\n",
      "| North|Product A|1/2/2022|      110|   1200|     10.91|      11.0|         -0.82|\n",
      "| North|Product B|1/2/2022|      140|   1800|     12.86|      11.2|         12.91|\n",
      "| South|Product A|1/2/2022|      130|   1600|     12.31|      11.0|         10.64|\n",
      "| South|Product B|1/2/2022|       70|    900|     12.86|      11.2|         12.91|\n",
      "|  West|Product A|1/2/2022|      100|   1300|      13.0|      11.0|         15.38|\n",
      "|  West|Product B|1/2/2022|      190|   2400|     12.63|      11.2|         11.32|\n",
      "+------+---------+--------+---------+-------+----------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fb8af118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"sales_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f7f0ec20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_product_price = spark.sql(\"\"\"\n",
    "    SELECT Region, Product, AVG(unit_price) AS avg_product_price\n",
    "    FROM sales_data\n",
    "    GROUP BY Region, Product\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a914ea38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------------------+\n",
      "|Region|  Product| avg_product_price|\n",
      "+------+---------+------------------+\n",
      "| South|Product B|             12.86|\n",
      "|  West|Product B|12.565000000000001|\n",
      "| North|Product B|13.094999999999999|\n",
      "|  West|Product A|            13.165|\n",
      "| South|Product A|12.405000000000001|\n",
      "| North|Product A|             10.91|\n",
      "+------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_product_price.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d77c4dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_unit_price = spark.sql(\"\"\"\n",
    "    SELECT Region, MAX(unit_price) AS max_unit_price\n",
    "    FROM sales_data\n",
    "    GROUP BY Region\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8d59a4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|Region|max_unit_price|\n",
      "+------+--------------+\n",
      "| South|         12.86|\n",
      "|  West|         13.33|\n",
      "| North|         13.33|\n",
      "+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_unit_price.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6cc19864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+\n",
      "|Region|  Product|max_profit|\n",
      "+------+---------+----------+\n",
      "| South|Product B|     12.91|\n",
      "|  West|Product B|     11.32|\n",
      "| North|Product B|     15.98|\n",
      "|  West|Product A|     17.48|\n",
      "| South|Product A|      12.0|\n",
      "| North|Product A|     -0.82|\n",
      "+------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_profit_per_product = spark.sql(\"\"\"\n",
    "    SELECT Region, Product, MAX(profit_percent) AS max_profit\n",
    "    FROM sales_data\n",
    "    GROUP BY Region, Product\n",
    "\"\"\")\n",
    "\n",
    "max_profit_per_product.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "64c30cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- UnitsSold: integer (nullable = true)\n",
      " |-- Revenue: string (nullable = true)\n",
      " |-- unit_price: double (nullable = true)\n",
      " |-- cost_price: double (nullable = false)\n",
      " |-- profit_percent: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "922a93e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_host = 'salesdb.cluster-cwtacdgkluou.us-east-1.rds.amazonaws.com'\n",
    "db_name = 'abc_sales'\n",
    "db_user = 'postgres'\n",
    "db_password = 'postgres'\n",
    "db_port = '5432'\n",
    "    \n",
    "conn = psycopg2.connect(\n",
    "    host=db_host,\n",
    "    dbname=db_name,\n",
    "    user=db_user,\n",
    "    password=db_password,\n",
    "    port=db_port\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS public.abc_sales\n",
    "(\n",
    "id bigint NOT NULL GENERATED BY DEFAULT AS IDENTITY ( INCREMENT 1 START 1 MINVALUE 1 MAXVALUE 99999999999 CACHE 1 ),\n",
    "region character varying(20) COLLATE pg_catalog.\"default\",\n",
    "product character varying(20) COLLATE pg_catalog.\"default\",\n",
    "date timestamp without time zone,\n",
    "unitsold bigint,\n",
    "revenue character varying(50) COLLATE pg_catalog.\"default\",\n",
    "unit_price double precision,\n",
    "cost_price double precision,\n",
    "profit_percent double precision,\n",
    "CONSTRAINT abc_sales_pkey PRIMARY KEY (id)\n",
    "    )''')\n",
    "conn.commit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "22941660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values = df.collect()\n",
    "    \n",
    "for row in df_values:\n",
    "    cursor.execute('''INSERT INTO public.abc_sales (region, product, date, unitsold, revenue, unit_price, cost_price, profit_percent) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)''',     \n",
    "    (row['Region'],\n",
    "    row['Product'],\n",
    "    row['Date'],\n",
    "    row['UnitsSold'],\n",
    "    row['Revenue'],\n",
    "    row['unit_price'],\n",
    "    row['cost_price'],\n",
    "    row['profit_percent']))\n",
    "    conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0a55bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "18f5a447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.write.csv('D:/Custom_assignment/Data/outputFile', header=True,mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be2dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1c520ce9",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 123] The filename, directory name, or volume label syntax is incorrect: 'D:/Custom_assignment/Data/outputFile/*.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9752\\1590404332.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0ms3_file_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms3_folder_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'transformed_sales.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0ms3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbucket_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms3_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\boto3\\s3\\inject.py\u001b[0m in \u001b[0;36mupload_file\u001b[1;34m(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \"\"\"\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mS3Transfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtransfer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         return transfer.upload_file(\n\u001b[0m\u001b[0;32m    144\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[0mbucket\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBucket\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\boto3\\s3\\transfer.py\u001b[0m in \u001b[0;36mupload_file\u001b[1;34m(self, filename, bucket, key, callback, extra_args)\u001b[0m\n\u001b[0;32m    286\u001b[0m         )\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m         \u001b[1;31m# If a client error was raised, add the backwards compatibility layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[1;31m# that raises a S3UploadFailedError. These specific errors were only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\s3transfer\\futures.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[1;31m# however if a KeyboardInterrupt is raised we want want to exit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;31m# out of this and propagate the exception.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\s3transfer\\futures.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;31m# final result.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\s3transfer\\tasks.py\u001b[0m in \u001b[0;36m_main\u001b[1;34m(self, transfer_future, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[1;31m# Call the submit method to start submitting tasks to execute the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m             \u001b[1;31m# transfer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_submit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m             \u001b[1;31m# If there was an exception raised during the submission of task\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\s3transfer\\upload.py\u001b[0m in \u001b[0;36m_submit\u001b[1;34m(self, client, config, osutil, request_executor, transfer_future, bandwidth_limiter)\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[1;31m# Determine the size if it was not provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransfer_future\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mupload_input_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprovide_transfer_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;31m# Do a multipart upload if needed, otherwise do a regular put object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\s3transfer\\upload.py\u001b[0m in \u001b[0;36mprovide_transfer_size\u001b[1;34m(self, transfer_future)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprovide_transfer_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransfer_future\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         transfer_future.meta.provide_transfer_size(\n\u001b[1;32m--> 244\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_osutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_file_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m         )\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\s3transfer\\utils.py\u001b[0m in \u001b[0;36mget_file_size\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_file_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mopen_file_chunk_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_byte\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\genericpath.py\u001b[0m in \u001b[0;36mgetsize\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;34m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 123] The filename, directory name, or volume label syntax is incorrect: 'D:/Custom_assignment/Data/outputFile/*.csv'"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'savecsvintoprasads3bucket'\n",
    "s3_folder_path = 'ABC-Sales/'\n",
    "local_file_path = 'D:/Custom_assignment/Data/outputFile/*.csv'\n",
    "s3_file_path = s3_folder_path + 'transformed_sales.csv'\n",
    "\n",
    "s3.upload_file(local_file_path, bucket_name, s3_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b03ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
